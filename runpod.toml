# RunPod Serverless Build Configuration
# This file tells RunPod how to build and deploy your endpoint

[project]
name = "hallo3-video-generator"
base_image = "nvidia/cuda:12.1.1-cudnn8-devel-ubuntu22.04"
gpu_types = ["NVIDIA RTX 4090", "NVIDIA A100-SXM4-80GB", "NVIDIA A100 80GB PCIe"]

[build]
# Commands to run during image build
system_packages = [
    "python3.10",
    "python3.10-venv",
    "python3-pip",
    "git",
    "git-lfs",
    "ffmpeg",
    "libsm6",
    "libxext6",
    "libgl1-mesa-glx",
    "wget",
    "curl"
]

python_version = "3.10"

[build.commands]
# These run in order during build
setup = [
    "git clone https://github.com/fudan-generative-vision/hallo3.git /workspace/hallo3",
    "pip install --upgrade pip",
    "pip install -r /workspace/hallo3/requirements.txt",
    "pip install runpod huggingface_hub"
]

# Download models during build (cached in image)
models = [
    "huggingface-cli download fudan-generative-ai/hallo3 --local-dir /workspace/hallo3/pretrained_models"
]

[runtime]
handler_path = "handler.py"
working_directory = "/workspace"

[runtime.env]
PYTHONUNBUFFERED = "1"
CUDA_VISIBLE_DEVICES = "0"
